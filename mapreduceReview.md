# Map-Reduce

## Overview
1. Hadoop MapReduce is a software framework for easily writing applications which process vast amounts of data (multi-terabyte data-sets) in-parallel on large clusters (thousands of nodes) of commodity hardware in a reliable, fault-tolerant manner.
2. A __*MapReduce job*__ usually splits the input data-set into independent chunks which are processed by the  __*map tasks*__ in a completely parallel manner. The framework sorts the outputs of the maps, which are then input to the __*reduce tasks*__. The framework takes care of scheduling tasks, monitoring them and re-executes the failed tasks.
3. The MapReduce framework consists of a single __*master ResourceManager*__, one __*slave NodeManager*__ per cluster-node, and __*MRAppMaster*__ per application.

## Input & Output 
1. The MapReduce framework operates exclusively on <key, value> pairs, that is, the framework views the input to the job as a set of <key, value> pairs and produces a set of <key, value> pairs as the output of the job, conceivably of different types.
2. The __key__ and __value__ classes have to be serializable by the framework and hence need to implement the __Writable__ interface. Additionally, the key classes have to implement the __WritableComparable__ interface to facilitate sorting by the framework.
3. Input and Output types of a MapReduce job:
(input) <k1, v1> -> *__map__* -> <k2, v2> -> *__combine__* -> <k2, v2> -> *__reduce__* -> <k3, v3> (output)

## MapReduce - User Interfaces

### Mapper
1. Class *Mapper* maps input key/value pairs to a set of intermediate key/value pairs. The Hadoop MapReduce framework spawns one map task for each *__InputSplit__* generated by the *__InputFormat__* for the job. The number of maps is usually driven by the total size of the inputs, that is, the total number of blocks of the input files.
2. Application can perform __setup()__ and __cleanup()__. The process will be like: setup -> map -> cleanup. Same thing to recuder, setup -> reduce -> cleanup.
3. Users can optionally specify a *__combiner__*, via __Job.setCombinerClass(Class)__, to perform local aggregation of the intermediate outputs, which helps to cut down the amount of data transferred from the Mapper to the Reducer.
4. Users can control the grouping by specifying a __Comparator__ via __Job.setGroupingComparatorClass(Class)__. The total number of partitions is the same as the number of reduce __tasks__ for the job. 

### Reducer
1. The *__Mapper__* outputs are sorted and then partitioned per *__Reducer__*. The total number of partitions is the same as the number of *__reduce tasks__* for the *__job__*. Users can control which keys (and hence records) go to which __Reducer__ by implementing a custom Partitioner.
